% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CMII_functions.R
\name{MI}
\alias{MI}
\title{Mutual Informaiton}
\usage{
MI(X,Y,method=c("covariance","KDE"),unit=c("bits",
"nats","hartley","normalized"),pvalue=FALSE,permutation_times=100)
}
\arguments{
\item{X}{a numeric vector to test}

\item{Y}{a numeric vector to test}

\item{method}{choose an estimator method to test the mutual information: "covariance" or "KDE" (the default is "covariance").}

\item{unit}{The unit of the result: "bits", "nats", "hartley" and "normalized" (the default is "bits"). The normalized result will be between 0 and 1.}

\item{pvalue}{a logical value to determine whether to calculate the pvalue or not}

\item{permutation_times}{integral value to determin the permutation times in calculating p value.}
}
\value{
a numeric value of mutual information between X and Y
}
\description{
\code{MI} takes two continuous variables as input and calculate the mutual information between them in various units. Different from estimator method based on data discretization, this fucntion will use covarians transformation or density estimation to estimate the continuous probabilities distribution of x and y values.
}
\examples{
x=rnorm(100);y1=rnorm(100);y2=x+rnorm(100)
MI(x,y1)
MI(x,y2)
MI(x,y2,pvalue=TRUE)
}
\author{
Tong Yin
}
